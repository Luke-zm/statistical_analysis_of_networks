{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2\n",
    "\n",
    "This is the second assignment of this course, covering the materials from Weeks 4 to 7. It will count 20% towards your final grade. The maximal number of points you can achieve is 20.\n",
    "\n",
    "This file is both the problem set and your answer sheet. You need to add your code to the respective code cells, and then upload this notebook to Canvas.\n",
    "\n",
    "Submission deadline via Canvas is **Sunday, 27 September 2024, 23.59pm**. If you upload it a few days in advance, we will run the code and check if it works. If there are any issues, a message will be sent to you via Canvas.\n",
    "\n",
    "The solution to each problem is to be stored in the dictionary variable `ans`: Your answer to Problem 1 should be stored in `ans[1]`, your answer to Problem 2 should be stored in `ans[2]`, and so forth. If you do the coding in a separate place and only store the results in this notebook, you will not get any partial points in case your answer is wrong, so I encourage you to add the full code to this notebook. **Make sure the whole Jupyter Notebook runs without errors before submitting**. You can check this by pressing _Run All_ in the menu.\n",
    "\n",
    "For each problem, the number of points you can achieve is indicated in the question. Points are only given if the code runs error-free and the output is correct. Partial points may be given depending on the quality of the answer. It is also indicated whether you should use Python or R to solve the problem.\n",
    "\n",
    "**Ensure your notebook runs by pressing \"Run All\" before submitting.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rpy2.ipython extension is already loaded. To reload it, use:\n",
      "  %reload_ext rpy2.ipython\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE ANYTHING IN THIS CELL ###\n",
    "\n",
    "# Import some libraries\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "\n",
    "# Create your answer dictionary\n",
    "ans = dict()\n",
    "\n",
    "# Load the rpy2 extension\n",
    "%load_ext rpy2.ipython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%R \n",
    "library(igraph)\n",
    "library(ergm)\n",
    "library(intergraph)\n",
    "library(network)\n",
    "library(sna)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1 \n",
    "\n",
    "[**1 point**, **Python**] Generate one thousand Erdős-Rényi graphs, each with $n=200$ nodes and edge probability $p=0.012$. For each graph, calculate the size of the largest component. Save the average of the largest component in `ans[1]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175.741\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR CODE BELOW ####\n",
    "# Step 1: Initialize variables\n",
    "num_graphs = 1000  # We need to generate 1000 graphs\n",
    "n = 200            # Number of nodes in each graph\n",
    "p = 0.012          # Probability of edge creation\n",
    "\n",
    "largest_component_sizes = []  # List to store the size of largest component in each graph\n",
    "\n",
    "# Step 2: Loop to generate graphs\n",
    "for i in range(num_graphs):\n",
    "    # Generate an Erdős-Rényi graph with n=200 nodes and edge probability p=0.012\n",
    "    G = nx.erdos_renyi_graph(n, p)\n",
    "    \n",
    "    # Step 3: Find the size of the largest connected component\n",
    "    largest_cc = max(nx.connected_components(G), key=len)\n",
    "    largest_component_size = len(largest_cc)\n",
    "    \n",
    "    # Step 4: Store the size of the largest component\n",
    "    largest_component_sizes.append(largest_component_size)\n",
    "\n",
    "# Step 5: Calculate the average size of the largest component\n",
    "average_largest_component_size = float(np.mean(largest_component_sizes))\n",
    "\n",
    "\n",
    "# Change the line below to store your answer\n",
    "ans[1] = average_largest_component_size\n",
    "print(ans[1])  # Output the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2\n",
    "\n",
    "[**1 point**, **Python**] Assume an Erdős-Rényi graph on $n=143,542$ nodes. How do you need to choose the edge connection probability $p$ so that the expected number of triangles equals $5,262$? Save your answer in `ans[2]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00040010607668908906\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR CODE BELOW ####\n",
    "# Given values\n",
    "n = 143542  # Number of nodes\n",
    "expected_triangles = 5262  # Expected number of triangles\n",
    "\n",
    "# Step 1: Calculate the binomial coefficient n choose 3\n",
    "binomial_coefficient = (n * (n - 1) * (n - 2)) / 6\n",
    "\n",
    "# Step 2: Rearrange the equation to solve for p^3 and then p\n",
    "p_cubed = (6 * expected_triangles) / binomial_coefficient\n",
    "\n",
    "# Step 3: Compute p by taking the cube root\n",
    "p = p_cubed ** (1 / 3)\n",
    "\n",
    "# Step 4: Convert p to a standard Python float\n",
    "p = float(p)\n",
    "\n",
    "# Change the line below to store your answer\n",
    "ans[2] = p\n",
    "print(ans[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3\n",
    "\n",
    "[**1 point**, **Python**] Assume the situation from Problem 2. In that graph, how close is the degree distribution to a Poisson distribution with parameter being the expected degree? Give an upper bound for the total variation metric and save it in `ans[3]`. _Take note that the total variation metric is defined as half the absolute differences between the point probabilities of the two distributions._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.007660499317213258\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR CODE HERE ####\n",
    "import scipy.stats as stats\n",
    "# Given parameters\n",
    "n = 143542  # Number of nodes\n",
    "p = 0.00040010607668908906  # Correct value of p from Problem 2\n",
    "num_bins = 100  # We'll use 100 bins for degree distribution comparison\n",
    "\n",
    "# Step 1: Compute the expected degree\n",
    "expected_degree = p * (n - 1)\n",
    "\n",
    "# Step 2: Generate an Erdős-Rényi graph with n nodes and edge probability p\n",
    "G = nx.erdos_renyi_graph(n, p)\n",
    "\n",
    "# Step 3: Get the degree distribution of the graph\n",
    "degrees = [deg for node, deg in G.degree()]  # List of degrees of each node\n",
    "\n",
    "# Step 4: Create a histogram for the degree distribution\n",
    "degree_hist, degree_bins = np.histogram(degrees, bins=num_bins, range=(0, num_bins), density=True)\n",
    "\n",
    "# Step 5: Create the Poisson distribution with lambda = expected_degree\n",
    "poisson_dist = stats.poisson.pmf(np.arange(num_bins), expected_degree)\n",
    "\n",
    "# Step 6: Compute the total variation metric\n",
    "total_variation = 0.5 * np.sum(np.abs(degree_hist - poisson_dist))\n",
    "\n",
    "# Step 7: Convert total variation metric to standard Python float\n",
    "total_variation = float(total_variation)\n",
    "\n",
    "# Change the line below to store your answer\n",
    "ans[3] = total_variation\n",
    "print(ans[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Given parameters\n",
    "n = 143542  # Number of nodes\n",
    "p = 0.00040010607668908906  # Correct value of p from Problem 2\n",
    "expected_degree = p * (n - 1)  # Expected degree (mean of Poisson)\n",
    "\n",
    "# Set up maximum degree range for comparison\n",
    "max_degree = 100  # Let's use degrees from 0 to 100 for approximation\n",
    "\n",
    "# Step 1: Compute the binomial distribution (degree distribution in Erdős-Rényi)\n",
    "binom_dist = stats.binom.pmf(np.arange(max_degree), n-1, p)\n",
    "\n",
    "# Step 2: Compute the Poisson distribution with lambda = expected_degree\n",
    "poisson_dist = stats.poisson.pmf(np.arange(max_degree), expected_degree)\n",
    "\n",
    "# Step 3: Compute the total variation metric\n",
    "total_variation = 0.5 * np.sum(np.abs(binom_dist - poisson_dist))\n",
    "\n",
    "# Step 4: Convert total variation metric to standard Python float\n",
    "total_variation = float(total_variation)\n",
    "\n",
    "# Store the result in ans[3] as required\n",
    "# ans[3] = total_variation\n",
    "print(total_variation)  # Output the result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 4\n",
    "\n",
    "[**1 point**, **Python**] Simulate 500 Erdős-Rényi graphs with $n=400$ nodes and edge probability $p=0.002$. For each graph, calculate the number of components. Save the average number of components in `ans[4]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241.07\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR CODE BELOW ####\n",
    "# List to store the number of components in each graph\n",
    "num_components_list = []\n",
    "n = 400\n",
    "p = 0.002\n",
    "\n",
    "# Step 1: Loop to generate graphs and count components\n",
    "for i in range(num_graphs):\n",
    "    # Generate an Erdős-Rényi graph with n=400 and p=0.002\n",
    "    G = nx.erdos_renyi_graph(n, p)\n",
    "    \n",
    "    # Step 2: Count the number of connected components in the graph\n",
    "    num_components = nx.number_connected_components(G)\n",
    "    \n",
    "    # Step 3: Store the number of components\n",
    "    num_components_list.append(num_components)\n",
    "\n",
    "# Step 4: Calculate the average number of components across all graphs\n",
    "average_num_components = float(np.mean(num_components_list))\n",
    "\n",
    "# Change the line below to store your answer\n",
    "ans[4] = average_num_components\n",
    "print(ans[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 5/6\n",
    "\n",
    "[**2 point** (1 point each), **Python**] Simulate 500 realisations of the configuration multigraph model on $n=100$ nodes. Assume the degree distribution is given as follows:\n",
    "- 10 nodes have degree 1\n",
    "- 20 nodes have degree 2\n",
    "- 30 nodes have degree 3\n",
    "- 20 nodes have degree 4\n",
    "- 10 nodes have degree 10\n",
    "- 10 nodes have degree 20\n",
    "\n",
    "For each realisation, calculate the number self-loops. Save the average number of self-loops over all realisations in `ans[5]`. For each realisation, also calculate the number of pairs of distinct vertices that are connected by more than one edge. Save the average number of such pairs over all realisations in `ans[6]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.474\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR CODE BELOW ####\n",
    "# Given degree distribution\n",
    "degree_sequence = [1]*10 + [2]*20 + [3]*30 + [4]*20 + [10]*10 + [20]*10\n",
    "\n",
    "# Number of nodes\n",
    "n = 100\n",
    "\n",
    "# Number of realizations\n",
    "num_realizations = 500\n",
    "\n",
    "# Variables to accumulate results\n",
    "self_loops = []\n",
    "multiple_edges = []\n",
    "\n",
    "# Step 1: Simulate 500 realizations of the configuration multigraph model\n",
    "for _ in range(num_realizations):\n",
    "    # Generate the multigraph with the given degree distribution\n",
    "    G = nx.configuration_model(degree_sequence, create_using=nx.MultiGraph)\n",
    "\n",
    "    # Remove parallel edges to make degree calculation easier\n",
    "    G = nx.Graph(G)  # Convert to a simple graph\n",
    "    \n",
    "    # Step 2: Calculate the number of self-loops\n",
    "    self_loop_count = sum(1 for u, v in G.edges() if u == v)\n",
    "    self_loops.append(self_loop_count)\n",
    "\n",
    "    # Step 3: Calculate the number of distinct vertex pairs with more than one edge\n",
    "    multiple_edge_count = sum(1 for u, v, weight in G.edges(data=True) if G.number_of_edges(u, v) > 1)\n",
    "    multiple_edges.append(multiple_edge_count)\n",
    "\n",
    "# Step 4: Compute the averages\n",
    "average_self_loops = float(np.mean(self_loops))\n",
    "average_multiple_edges = float(np.mean(multiple_edges))\n",
    "\n",
    "# Change the line below to store your answer\n",
    "ans[5] = average_self_loops\n",
    "ans[6] = average_multiple_edges\n",
    "print(ans[5])\n",
    "print(ans[6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 7\n",
    "\n",
    "[**2 point**, **Python**] For a configuration multigraph with degree distribution as in Problem 5, calculate the threshold quantity that determines whether the graph has, with high probability, a giant component or not. Save your answer in `ans[7]`. _We are looking for the quantity where the threshold to distinguish between the two cases is $1$._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.923076923076922\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR CODE BELOW ####\n",
    "# Given degree distribution\n",
    "degree_sequence = [1]*10 + [2]*20 + [3]*30 + [4]*20 + [10]*10 + [20]*10\n",
    "\n",
    "# Step 1: Compute the average degree (mean of the degree distribution)\n",
    "average_degree = np.mean(degree_sequence)\n",
    "\n",
    "# Step 2: Compute the second moment (mean of the squares of the degrees)\n",
    "second_moment_degree = np.mean(np.square(degree_sequence))\n",
    "\n",
    "# Step 3: Compute the threshold quantity\n",
    "threshold_quantity = second_moment_degree / average_degree\n",
    "\n",
    "# Change the line below to store your answer\n",
    "ans[7] = float(threshold_quantity)\n",
    "print(ans[7])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 8\n",
    "\n",
    "Download the file of your first graph from `https://nus-st5225.netlify.app/assignments/2/e1234567/graph_1.graphml`, where you need to replace `e1234567` by your Canvas login ID. The file is a GraphML file containing the graph. Save the file in the **same directory as this notebook** and **do not change the name of the file**! The code to load the graph as networkx graph is given below. The graph is stored in the variable `G1`. Do not change the code.\n",
    "\n",
    "[**2 points**, **Python**]  Use the `powerlaw` package to fit a power-law distribution to the degree distribution of the graph `G1`. Let the algorithm choose $x_{\\min}$ on its own. Save the fitted exponent in `ans[8]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0303780884100178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "G1 = nx.read_graphml('graph_1.graphml')\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR CODE BELOW ####\n",
    "import powerlaw\n",
    "# Step 2: Compute the degree distribution\n",
    "degrees = [deg for _, deg in G1.degree()]\n",
    "\n",
    "# Step 3: Fit a power-law distribution to the degree data\n",
    "fit = powerlaw.Fit(degrees)\n",
    "\n",
    "# Step 4: Extract the fitted exponent (alpha)\n",
    "fitted_exponent = fit.power_law.alpha\n",
    "\n",
    "# Change the line below to store your answer\n",
    "ans[8] = float(fitted_exponent)\n",
    "print(ans[8])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems 9/10/11\n",
    "\n",
    "[**3 points** (1 point each), **Python**] Use the method described on page 8 of the paper [this paper](https://arxiv.org/pdf/1305.0215) to determine whether a power law distribution fits the degree distribution of `G1` significantly better than an exponential distribution. Ensure the method returns the normalised loglikelihood ratio test statistic `R`. Store this statistic in `ans[9]`. The function also returns a $p$-value, which you should store in `ans[10]`. Then, determine whether the power law distribution fits significantly better than the exponential distribution. Save the result in `ans[11]`, where `True` means that the power law distribution fits better, and `False` means that the exponential distribution fits significantly better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87.8683881481307\n",
      "1.4799257005403976e-06\n",
      "True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calculating best minimal value for power law fit\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR CODE BELOW ####\n",
    "# Step 1: Compute the degree distribution of the graph `G1`\n",
    "degrees = [deg for _, deg in G1.degree()]\n",
    "\n",
    "# Step 2: Fit both power-law and exponential distributions to the data\n",
    "fit = powerlaw.Fit(degrees)\n",
    "\n",
    "# Step 3: Perform the loglikelihood ratio test between power-law and exponential distribution\n",
    "R, p_value = fit.distribution_compare('power_law', 'exponential')\n",
    "\n",
    "# Step 4: Determine if the power-law fits significantly better than the exponential distribution\n",
    "best_fit = True if p_value < 0.05 and R > 0 else False\n",
    "\n",
    "# Change the line below to store your answer\n",
    "ans[9] = float(R)        # Loglikelihood ratio\n",
    "ans[10] = float(p_value) # p-value\n",
    "ans[11] = best_fit       # True if power-law fits better, False otherwise\n",
    "print(ans[9])\n",
    "print(ans[10])\n",
    "print(ans[11])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 12\n",
    "\n",
    "Download the file of your second graph from `https://nus-st5225.netlify.app/assignments/2/e1234567/graph_2.graphml`, where you need to replace `e1234567` by your Canvas login ID. The file is a GraphML file containing the graph. Save the file in the **same directory as this notebook** and **do not change the name of the file**! The code to load the graph as networkx graph is given below. The graph is stored in the variable `G2`. Do not change the code. \n",
    "\n",
    "[**2 point**, **Python**] Use the Louvain method from the `networkx` package to maximise the modularity in the graph `G2`. Save the maximised modularity in `ans[12]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.46346347561156725\n"
     ]
    }
   ],
   "source": [
    "\n",
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "G2 = nx.read_graphml('graph_2.graphml')\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR CODE BELOW ####\n",
    "# Step 1: Apply the Louvain method to detect communities and maximize modularity\n",
    "communities = nx.community.louvain_communities(G2)\n",
    "\n",
    "# Step 2: Calculate the modularity of the partition\n",
    "modularity_value = nx.community.modularity(G2, communities)\n",
    "\n",
    "# Change the line below to store your answer\n",
    "ans[12] = float(modularity_value)\n",
    "print(ans[12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 13/14\n",
    "\n",
    "[**2 points** (1 point each), **Python**] Assume the graph was generated from a Stochastic Block Model. Using the partition obtained in the previous problem, derive the MLE estimator of the connection probability matrix. Save the largest diagonal entry of the connection probability matrix in `ans[13]`, and save the largest off-diagonal entry in `ans[14]`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.29421990438939594\n",
      "0.051353874883286646\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "G2 = nx.read_graphml('graph_2.graphml')\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR CODE BELOW ####\n",
    "from itertools import combinations\n",
    "from collections import defaultdict\n",
    "\n",
    "# Step 1: Use the partition obtained from Problem 12\n",
    "communities = nx.community.louvain_communities(G2, seed=123)\n",
    "\n",
    "# Create a dictionary to map each node to its community\n",
    "node_to_community = {}\n",
    "for idx, community in enumerate(communities):\n",
    "    for node in community:\n",
    "        node_to_community[node] = idx\n",
    "\n",
    "# Step 2: Initialize connection counts and total possible edges between communities\n",
    "community_size = defaultdict(int)  # Track the number of nodes in each community\n",
    "edge_count = defaultdict(lambda: defaultdict(int))  # Track the number of edges between communities\n",
    "\n",
    "# Step 3: Count edges between communities\n",
    "for u, v in G2.edges():\n",
    "    c_u = node_to_community[u]\n",
    "    c_v = node_to_community[v]\n",
    "    edge_count[c_u][c_v] += 1\n",
    "\n",
    "# Step 4: Compute the connection probability matrix\n",
    "num_communities = len(communities)\n",
    "prob_matrix = np.zeros((num_communities, num_communities))\n",
    "\n",
    "for i in range(num_communities):\n",
    "    for j in range(i, num_communities):\n",
    "        if i == j:\n",
    "            # Intra-community connections\n",
    "            num_possible_edges = len(communities[i]) * (len(communities[i]) - 1) / 2\n",
    "        else:\n",
    "            # Inter-community connections\n",
    "            num_possible_edges = len(communities[i]) * len(communities[j])\n",
    "        if num_possible_edges > 0:\n",
    "            prob_matrix[i, j] = edge_count[i][j] / num_possible_edges\n",
    "            prob_matrix[j, i] = prob_matrix[i, j]  # Symmetric matrix\n",
    "\n",
    "# Step 5: Find the largest diagonal entry and the largest off-diagonal entry\n",
    "largest_diagonal = np.max(np.diag(prob_matrix))\n",
    "largest_off_diagonal = np.max(prob_matrix - np.diag(np.diag(prob_matrix)))\n",
    "\n",
    "# Change the line below to store your answer\n",
    "ans[13] = float(largest_diagonal)\n",
    "ans[14] = float(largest_off_diagonal)\n",
    "\n",
    "print(ans[13])\n",
    "print(ans[14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems 15\n",
    "\n",
    "[**1 point**, **Python**] Looking at the estimated connection probability matrix from the previous problem, determine whether the graph is\n",
    "(1) assortative, (2) disassortative, or (3) core-periphery. Save the result in `ans[15]` as number 1, 2, or 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "random.seed(123)\n",
    "np.random.seed(123)\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR CODE BELOW ####\n",
    "# Compare largest diagonal entry with largest off-diagonal entry\n",
    "if ans[13] > ans[14]:\n",
    "    # Higher within-community connections => assortative\n",
    "    ans[15] = 1\n",
    "elif ans[13] < ans[14]:\n",
    "    # Higher between-community connections => disassortative\n",
    "    ans[15] = 2\n",
    "else:\n",
    "    # Mixed structure, suggestive of core-periphery\n",
    "    ans[15] = 3\n",
    "\n",
    "# Change the line below to store your answer\n",
    "print(ans[15])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 16\n",
    "\n",
    "[**2 point**, **R**] Use the `ergm` package in R to fit an Exponential Random Graph Model to the graph `G2` with only `edges` term. Save the estimated coefficient of the edge term in `ans_16`. _Please note that the variable name is different from the previous problems. It will be exported to Python and stored in `ans[16]` automatically._ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Load the graph from the GraphML file\n",
    "graphml_file_path = 'graph_2.graphml'\n",
    "G2 = nx.read_graphml(graphml_file_path)\n",
    "\n",
    "# Convert the graph to an edge list and save it as a CSV file\n",
    "nx.write_edgelist(G2, \"graph_2_edgelist.csv\", delimiter=\",\", data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    edges \n",
      "-2.476884 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Starting maximum pseudolikelihood estimation (MPLE):\n",
       "Obtaining the responsible dyads.\n",
       "Evaluating the predictor and response matrix.\n",
       "Maximizing the pseudolikelihood.\n",
       "Finished MPLE.\n",
       "Evaluating log-likelihood at the estimate. \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%R\n",
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "# library(igraph)\n",
    "# library(intergraph)\n",
    "# library(ergm)\n",
    "# set.seed(123)\n",
    "# G2_ <- read_graph('graph_2.graphml', format='graphml')\n",
    "# G2 <- asNetwork(G2_)\n",
    "#### END OF PART THAT SHOULD NOT BE MODIFIED ####\n",
    "\n",
    "#### ADD YOUR R CODE BELOW ####\n",
    "### DO NOT CHANGE THE LINES BELOW ###\n",
    "library(igraph)\n",
    "library(intergraph)\n",
    "library(ergm)\n",
    "set.seed(123)\n",
    "\n",
    "# Step 1: Load the edge list from the CSV file as an igraph object\n",
    "G2_edges <- read.csv('graph_2_edgelist.csv', header=FALSE)\n",
    "G2_graph <- graph_from_edgelist(as.matrix(G2_edges), directed=FALSE)\n",
    "\n",
    "# Convert the igraph object to a network object for ERGM\n",
    "G2 <- asNetwork(G2_graph)\n",
    "\n",
    "# Step 2: Fit the ERGM with the 'edges' term\n",
    "model <- ergm(G2 ~ edges)\n",
    "\n",
    "# Step 3: Extract the estimated coefficient for the edges term\n",
    "ans_16 <- coef(model)[\"edges\"]\n",
    "\n",
    "# Output the result\n",
    "print(ans_16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.476883684116791\n"
     ]
    }
   ],
   "source": [
    "### DO NOT CHANGE THE CODE BELOW ###\n",
    "%R -o ans_16\n",
    "ans[16] = ans_16[0]\n",
    "print(ans[16])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensure your notebook runs by pressing \"Run All\" before submitting.**\n",
    "\n",
    "# END OF ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### DO NOT CHANGE ANYTHING BELOW THIS LINE ####\n",
    "import json\n",
    "\n",
    "# Save the dictionary as JSON\n",
    "with open('solutions.json', 'w') as file:\n",
    "  json.dump(ans, file, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ST5225",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
